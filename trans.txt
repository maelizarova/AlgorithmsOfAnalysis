import pandas as pd
import numpy as np
from typing import Dict, List, Union, Any, Tuple, Optional
from sklearn.base import BaseEstimator
from sklearn.metrics import get_scorer
from sklearn.preprocessing import OrdinalEncoder

def select_top_features_with_eval_set(
    data: pd.DataFrame,
    targets: List[str],
    model: BaseEstimator,
    n_top: int = 10,
    categorical_features: Optional[List[str]] = None,
    preprocess_categorical: bool = True,
    metric: Optional[Union[str, callable]] = None,
    greater_is_better: Optional[bool] = None,
    eval_set: Optional[Tuple[pd.DataFrame, pd.Series]] = None,
    early_stopping_rounds: Optional[int] = None,
    random_state: int = 42,
    verbose: bool = False,
    **fit_params: Any
) -> Dict[str, List[str]]:
    """
    Отбирает топ-N фичей для каждого таргета с поддержкой:
    - Явной передачи eval_set
    - Ранней остановки (early_stopping_rounds)
    - Категориальных фичей
    - Любых моделей (LightGBM, CatBoost, XGBoost, etc.)

    Параметры:
    ----------
    eval_set : Tuple[X_valid, y_valid], optional
        Валидационный набор в формате (X, y).
    early_stopping_rounds : int, optional
        Количество раундов без улучшения для остановки.
    **fit_params : Any
        Доп. параметры для model.fit() (например, eval_metric для LightGBM).
    """
    top_features = {}
    
    for target in targets:
        X = data.drop(columns=targets)
        y = data[target]
        
        # Обработка категориальных фичей
        if categorical_features is None:
            categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
        
        if preprocess_categorical and categorical_features:
            encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
            X[categorical_features] = encoder.fit_transform(X[categorical_features])
            if eval_set is not None:
                X_valid, y_valid = eval_set
                X_valid[categorical_features] = encoder.transform(X_valid[categorical_features])
        
        # Подготовка eval_set
        if eval_set is not None:
            X_valid, y_valid = eval_set
            if hasattr(model, 'fit'):
                # Для LightGBM/XGBoost/CatBoost
                fit_params['eval_set'] = [(X_valid, y_valid)]
                if early_stopping_rounds:
                    fit_params['early_stopping_rounds'] = early_stopping_rounds
        
        # Обучение модели
        model.set_params(random_state=random_state)
        if verbose:
            print(f"Training for target: {target}")
        
        model.fit(X, y, **fit_params)
        
        # Получение важности фичей
        if hasattr(model, 'feature_importances_'):
            importance = model.feature_importances_
        elif metric is not None:
            from sklearn.inspection import permutation_importance
            scorer = get_scorer(metric) if isinstance(metric, str) else metric
            result = permutation_importance(model, X, y, scoring=scorer, n_repeats=5, random_state=random_state)
            importance = result.importances_mean
        else:
            raise ValueError("Model has no feature_importances_ and no metric provided.")
        
        # Топ-N фичей
        top_features[target] = pd.DataFrame({
            'feature': X.columns,
            'importance': importance
        }).sort_values('importance', ascending=False).head(n_top)['feature'].tolist()
    
    return top_features

from lightgbm import LGBMRegressor
from sklearn.model_selection import train_test_split

# Подготовка данных
X_train, X_val, y_train, y_val = train_test_split(
    data.drop(columns=['sales', 'revenue']),
    data['sales'],
    test_size=0.2,
    random_state=42
)

# Модель и вызов функции
model = LGBMRegressor(n_estimators=1000)
selected_features = select_top_features_with_eval_set(
    data=data,  # Весь датасет (для обучения)
    targets=['sales', 'revenue'],
    model=model,
    eval_set=(X_val, y_val),  # Передаем явно
    early_stopping_rounds=50,
    fit_params={'eval_metric': 'rmse', 'verbose': 10}
)
