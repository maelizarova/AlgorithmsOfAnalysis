from typing import Dict, List, Union, Any, Optional
import pandas as pd
import numpy as np
import os
from sklearn.base import BaseEstimator
from sklearn.model_selection import GridSearchCV
from sklearn2pmml import sklearn2pmml, make_pmml_pipeline
from sklearn.metrics import get_scorer
from lightgbm import early_stopping, log_evaluation


def grid_search_with_splits(
    train_data: pd.DataFrame,
    test_data: pd.DataFrame,
    oot_data: pd.DataFrame,
    targets: List[str],
    final_selected_features: Dict[str, List[str]],
    model: BaseEstimator,
    categorical_features: Optional[List[str]] = None,
    task_type: str = 'classification',
    param_grid: Optional[Dict[str, List[Any]]] = None,
    scoring: Optional[Union[str, List[str], Dict[str, Any]]] = None,
    cv: int = 5,
    threads: int = -1,
    pmml_output_path: Optional[str] = None,
    early_stopping_rounds: Optional[int] = None,
    verbose: int = 0
) -> Dict[str, Dict[str, Any]]:
    """
    Универсальная функция для подбора моделей без использования Pipeline
    
    Параметры:
        train_data: Тренировочные данные
        test_data: Валидационные данные
        oot_data: Out-of-time данные
        targets: Список целевых переменных
        final_selected_features: Словарь {target: [фичи]}
        model: Экземпляр модели (sklearn-совместимый)
        categorical_features: Список категориальных фичей
        task_type: 'classification' или 'regression'
        param_grid: Сетка параметров
        scoring: Метрики оценки
        cv: Число фолдов
        threads: Число потоков
        pmml_output_path: Путь для сохранения PMML
        early_stopping_rounds: Раунды ранней остановки
        verbose: Уровень логгирования
    """
    # Инициализация параметров
    categorical_features = categorical_features or []
    param_grid = param_grid or {}
    scoring = scoring or ('roc_auc' if task_type == 'classification' else 'neg_mean_squared_error')
    results = {}

    for target in targets:
        print(f"\n=== Обработка целевой переменной: {target} ===")
        
        # 1. Подготовка данных
        features = final_selected_features[target]
        cat_features = [f for f in categorical_features if f in features]
        
        # 2. Определение типа модели
        model_type = type(model).__name__.lower()
        is_lgbm = 'lgbm' in model_type
        is_catboost = 'catboost' in model_type
        
        # 3. Обработка категориальных признаков
        if cat_features and (is_lgbm or is_catboost):
            for df in [train_data, test_data, oot_data]:
                for col in cat_features:
                    df[col] = df[col].astype('category')
            
            if is_lgbm:
                # Для LightGBM передаем индексы категориальных фичей
                cat_indices = [features.index(f) for f in cat_features]
                model.set_params(**{'categorical_feature': cat_indices})
            elif is_catboost:
                # Для CatBoost передаем имена фичей
                model.set_params(cat_features=cat_features)

        # 4. Настройка параметров обучения
        fit_params = {}
        if early_stopping_rounds and (is_lgbm or is_catboost):
            fit_params['eval_set'] = [(test_data[features], test_data[target])]
            
            if is_lgbm:
                fit_params['callbacks'] = [
                    early_stopping(early_stopping_rounds, verbose=verbose),
                    log_evaluation(verbose) if verbose > 0 else None
                ]
                fit_params['eval_metric'] = 'binary_logloss' if task_type == 'classification' else 'l2'
            elif is_catboost:
                fit_params['early_stopping_rounds'] = early_stopping_rounds

        # 5. Настройка GridSearch
        grid_search = GridSearchCV(
            estimator=model,
            param_grid=param_grid,
            scoring=scoring,
            cv=cv,
            n_jobs=1 if threads != 1 else threads,  # Осторожно с многопоточностью
            verbose=verbose,
            error_score='raise'
        )

        # 6. Обучение модели
        print(f"Обучение модели {model_type} на {len(features)} фичах...")
        grid_search.fit(train_data[features], train_data[target], **fit_params)
        
        # 7. Получение лучшей модели
        best_model = grid_search.best_estimator_
        
        # 8. Вычисление метрик
        metrics = {}
        for name, df in [('train', train_data), ('test', test_data), ('oot', oot_data)]:
            X, y = df[features], df[target]
            pred = best_model.predict(X)
            
            if task_type == 'classification':
                from sklearn.metrics import (accuracy_score, precision_score, 
                                          recall_score, f1_score, roc_auc_score)
                metrics[name] = {
                    'accuracy': accuracy_score(y, pred),
                    'precision': precision_score(y, pred),
                    'recall': recall_score(y, pred),
                    'f1': f1_score(y, pred),
                    'roc_auc': roc_auc_score(y, pred)
                }
            else:
                from sklearn.metrics import (mean_squared_error, mean_absolute_error,
                                          mean_absolute_percentage_error, r2_score)
                metrics[name] = {
                    'mse': mean_squared_error(y, pred),
                    'rmse': np.sqrt(mean_squared_error(y, pred)),
                    'mae': mean_absolute_error(y, pred),
                    'mape': mean_absolute_percentage_error(y, pred),
                    'r2': r2_score(y, pred)
                }

        # 9. Сохранение в PMML
        if pmml_output_path:
            os.makedirs(pmml_output_path, exist_ok=True)
            output_file = f"{pmml_output_path}/{target}_{model_type}.pmml"
            
            # Создаем минимальный PMML pipeline для экспорта
            pmml_pipeline = make_pmml_pipeline(best_model)
            sklearn2pmml(pmml_pipeline, output_file, with_repr=True)
            
            print(f"Модель сохранена в {output_file}")

        # 10. Сохранение результатов
        results[target] = {
            'model': best_model,
            'metrics': metrics,
            'best_params': grid_search.best_params_,
            'features': features,
            'categorical_features': cat_features,
            'model_type': model_type
        }

        # 11. Вывод результатов
        print("\nЛучшие параметры:")
        for param, value in grid_search.best_params_.items():
            print(f"{param}: {value}")
        
        print("\nМетрики:")
        for dataset in ['train', 'test', 'oot']:
            print(f"\n{dataset.upper()}:")
            for metric, value in metrics[dataset].items():
                print(f"{metric}: {value:.4f}")

    return results
