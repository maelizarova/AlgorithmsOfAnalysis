def select_top_features_with_eval_set(
    data: pd.DataFrame,
    targets: List[str],
    model: BaseEstimator,
    eval_set: Optional[pd.DataFrame] = None,
    n_top: int = 10,
    categorical_features: Optional[List[str]] = None,
    preprocess_categorical: bool = True,
    early_stopping_rounds: Optional[int] = None,
    random_state: int = 42,
    fit_params: Optional[dict] = None
) -> Dict[str, List[str]]:
    """
    Функция с исправленной обработкой категориальных признаков.
    """
    top_features = {}
    
    if fit_params is None:
        fit_params = {}
    
    for target in targets:
        # Подготовка данных
        X = data.drop(columns=targets)
        y = data[target]
        
        # Определение категориальных фичей
        if categorical_features is None:
            categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # Обработка категориальных признаков
        if categorical_features:
            if preprocess_categorical:
                # Кодирование категорий для моделей, которые не поддерживают их напрямую
                encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
                X[categorical_features] = encoder.fit_transform(X[categorical_features])
            else:
                # Для LightGBM/CatBoost преобразуем в category
                for col in categorical_features:
                    X[col] = X[col].astype('category')
        
        # Подготовка eval_set
        current_fit_params = fit_params.copy()
        
        if eval_set is not None:
            X_valid = eval_set.drop(columns=targets)
            y_valid = eval_set[target]
            
            if categorical_features:
                if preprocess_categorical:
                    X_valid[categorical_features] = encoder.transform(X_valid[categorical_features])
                else:
                    for col in categorical_features:
                        X_valid[col] = X_valid[col].astype('category')
            
            current_fit_params['eval_set'] = [(X_valid, y_valid)]
            
            if early_stopping_rounds:
                if 'LGBM' in model.__class__.__name__:
                    current_fit_params['callbacks'] = [early_stopping(early_stopping_rounds)]
                else:
                    current_fit_params['early_stopping_rounds'] = early_stopping_rounds
        
        # Для LightGBM явно указываем категориальные признаки
        if 'LGBM' in model.__class__.__name__ and not preprocess_categorical:
            current_fit_params['categorical_feature'] = categorical_features
        
        # Обучение модели
        model.set_params(random_state=random_state)
        model.fit(X, y, **current_fit_params)
        
        # Получение важности фичей
        if hasattr(model, 'feature_importances_'):
            importance = model.feature_importances_
        else:
            from sklearn.inspection import permutation_importance
            metric = current_fit_params.get('eval_metric', 'rmse')
            scorer = get_scorer(metric) if isinstance(metric, str) else metric
            result = permutation_importance(
                model, X, y, scoring=scorer, n_repeats=5, random_state=random_state
            )
            importance = result.importances_mean
        
        top_features[target] = pd.DataFrame({
            'feature': X.columns,
            'importance': importance
        }).sort_values('importance', ascending=False).head(n_top)['feature'].tolist()
    
    return top_features
