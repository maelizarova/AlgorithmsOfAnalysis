import pandas as pd
import numpy as np
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error

def select_top_features_by_target(
    data: pd.DataFrame,
    targets: list,
    n_top: int = 10,
    model_params: dict = None,
    importance_type: str = 'gain',
    random_state: int = 42,
) -> dict:
    """
    Отбирает топ-N самых важных фичей для каждого целевого признака (target) 
    с помощью LightGBM Regressor.

    Параметры:
    ----------
    data : pd.DataFrame
        Датасет с фичами и таргетами.
    targets : list
        Список целевых переменных (названия колонок).
    n_top : int, optional (default=10)
        Сколько фичей отбирать для каждого таргета.
    model_params : dict, optional
        Дополнительные параметры для LGBMRegressor (если None, используются дефолтные).
    importance_type : str, optional (default='gain')
        Тип важности фичей ('split' или 'gain').
    random_state : int, optional (default=42)
        Seed для воспроизводимости.

    Возвращает:
    -----------
    dict
        Словарь вида {target: list_of_top_features}.
    """
    if model_params is None:
        model_params = {
            'n_estimators': 100,
            'random_state': random_state,
            'importance_type': importance_type,
        }

    top_features = {}

    for target in targets:
        # Разделяем на X и y (удаляем другие таргеты, чтобы они не попали в фичи)
        X = data.drop(columns=targets)
        y = data[target]

        # Обучаем модель
        model = LGBMRegressor(**model_params)
        model.fit(X, y)

        # Получаем важность фичей и сортируем
        importance = pd.DataFrame({
            'feature': X.columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)

        # Сохраняем топ-N фичей
        top_features[target] = importance['feature'].head(n_top).tolist()

    return top_features

# Допустим, у нас есть датасет `df` с фичами и несколькими таргетами ['target1', 'target2']
targets = ['target1', 'target2']

# Вызываем функцию
selected_features = select_top_features_by_target(
    data=df,
    targets=targets,
    n_top=5,
    model_params={'n_estimators': 200, 'max_depth': 5},
    importance_type='gain'
)

# Результат — словарь с топ-5 фичами для каждого таргета
print(selected_features)
# {'target1': ['feat_A', 'feat_B', ...], 'target2': ['feat_C', 'feat_D', ...]}
