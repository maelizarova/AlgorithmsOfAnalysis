from typing import Dict, List, Union, Any, Optional
import pandas as pd
import numpy as np
import os
from lightgbm import LGBMRegressor, LGBMClassifier, early_stopping, log_evaluation
from sklearn.model_selection import GridSearchCV
from sklearn2pmml import sklearn2pmml, make_pmml_pipeline
from sklearn.metrics import get_scorer

def grid_search_with_splits(
    train_data: pd.DataFrame,
    test_data: pd.DataFrame,
    oot_data: pd.DataFrame,
    targets: List[str],
    final_selected_features: Dict[str, List[str]],
    model_type: str = 'regression',
    categorical_features: Optional[List[str]] = None,
    param_grid: Optional[Dict[str, List[Any]]] = None,
    scoring: Optional[Union[str, List[str], Dict[str, Any]]] = None,
    cv: int = 5,
    threads: int = -1,
    pmml_output_path: Optional[str] = None,
    early_stopping_rounds: Optional[int] = None,
    verbose: int = 0
) -> Dict[str, Dict[str, Any]]:
    """
    Универсальная функция для подбора моделей LightGBM без использования Pipeline
    
    Параметры:
        train_data: Тренировочные данные
        test_data: Валидационные данные
        oot_data: Out-of-time данные
        targets: Список целевых переменных
        final_selected_features: Словарь {target: [фичи]}
        model_type: 'regression' или 'classification'
        categorical_features: Список категориальных фичей
        param_grid: Сетка параметров
        scoring: Метрики оценки
        cv: Число фолдов
        threads: Число потоков
        pmml_output_path: Путь для сохранения PMML
        early_stopping_rounds: Раунды ранней остановки
        verbose: Уровень логгирования
    """
    # Инициализация параметров
    categorical_features = categorical_features or []
    param_grid = param_grid or {}
    scoring = scoring or ('roc_auc' if model_type == 'classification' else 'neg_mean_squared_error')
    results = {}

    for target in targets:
        print(f"\n=== Обработка целевой переменной: {target} ===")
        
        # 1. Подготовка данных
        features = final_selected_features[target]
        cat_features = [f for f in categorical_features if f in features]
        
        # 2. Создание модели
        if model_type == 'classification':
            model = LGBMClassifier(random_state=42, verbose=-1, n_jobs=threads)
        else:
            model = LGBMRegressor(random_state=42, verbose=-1, n_jobs=threads)
        
        # 3. Указание категориальных фичей
        if cat_features:
            for df in [train_data, test_data, oot_data]:
                for col in cat_features:
                    df[col] = df[col].astype('category')
            
            # Для LightGBM нужно передать индексы категориальных фичей
            cat_indices = [i for i, f in enumerate(features) if f in cat_features]
            model.set_params(**{'categorical_feature': cat_indices})

        # 4. Настройка параметров обучения
        fit_params = {}
        if early_stopping_rounds:
            fit_params['eval_set'] = [(test_data[features], test_data[target])]
            fit_params['callbacks'] = [
                early_stopping(early_stopping_rounds, verbose=verbose),
                log_evaluation(verbose) if verbose > 0 else None
            ]

        # 5. Настройка GridSearch
        grid_search = GridSearchCV(
            estimator=model,
            param_grid=param_grid,
            scoring=scoring,
            cv=cv,
            n_jobs=1 if threads != 1 else threads,
            verbose=verbose
        )

        # 6. Обучение модели
        print(f"Обучение на {len(features)} фичах...")
        grid_search.fit(train_data[features], train_data[target], **fit_params)
        
        # 7. Получение лучшей модели
        best_model = grid_search.best_estimator_
        
        # 8. Вычисление метрик
        metrics = {}
        for name, df in [('train', train_data), ('test', test_data), ('oot', oot_data)]:
            X, y = df[features], df[target]
            pred = best_model.predict(X)
            
            if model_type == 'classification':
                metrics[name] = {
                    'accuracy': accuracy_score(y, pred),
                    'precision': precision_score(y, pred),
                    'recall': recall_score(y, pred),
                    'f1': f1_score(y, pred),
                    'roc_auc': roc_auc_score(y, pred)
                }
            else:
                metrics[name] = {
                    'mse': mean_squared_error(y, pred),
                    'rmse': np.sqrt(mean_squared_error(y, pred)),
                    'mae': mean_absolute_error(y, pred),
                    'r2': r2_score(y, pred)
                }

        # 9. Сохранение в PMML
        if pmml_output_path:
            os.makedirs(pmml_output_path, exist_ok=True)
            output_file = f"{pmml_output_path}/{target}_{model_type}.pmml"
            
            # Создаем минимальный PMML pipeline
            pmml_pipeline = make_pmml_pipeline(best_model)
            sklearn2pmml(pmml_pipeline, output_file, with_repr=True)
            
            print(f"Модель сохранена в {output_file}")

        # 10. Сохранение результатов
        results[target] = {
            'model': best_model,
            'metrics': metrics,
            'best_params': grid_search.best_params_,
            'features': features,
            'categorical_features': cat_features
        }

        # 11. Вывод результатов
        print("\nЛучшие параметры:")
        for param, value in grid_search.best_params_.items():
            print(f"{param}: {value}")
        
        print("\nМетрики:")
        for dataset in ['train', 'test', 'oot']:
            print(f"\n{dataset.upper()}:")
            for metric, value in metrics[dataset].items():
                print(f"{metric}: {value:.4f}")

    return results
