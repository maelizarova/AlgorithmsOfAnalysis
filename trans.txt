import numpy as np
from scipy import stats

def exact_ols_style_interval(model, X_train, y_train, X_new, alpha=0.05):
    """
    Жёстко воспроизводит OLS-формулу для интервала предсказания, 
    даже если модель нелинейная (LightGBM). 
    Внимание: Это формальная подстановка, а не теоретически обоснованный метод!

    Параметры:
    -----------
    model : любой модель (LightGBM, CatBoost и т.д.)
        Модель с методом predict().
    X_train : array-like
        Предикторы, использованные для обучения.
    y_train : array-like
        Целевая переменная.
    X_new : array-like
        Новые данные для предсказания.
    alpha : float
        Уровень значимости (0.05 = 95% интервал).

    Возвращает:
    -----------
    tuple : (y_pred, lower, upper)
    """
    # Добавляем константу к X_train и X_new (как в OLS)
    X_train_const = np.column_stack([np.ones(len(X_train)), X_train])
    X_new_const = np.column_stack([np.ones(len(X_new)), X_new])

    # Предсказания модели на обучающих данных
    y_pred_train = model.predict(X_train)
    residuals = y_train - y_pred_train
    sigma_e = np.std(residuals)

    # Формально вычисляем (X'X)⁻¹ как в OLS (игнорируя, что модель не OLS!)
    XtX_inv = np.linalg.pinv(X_train_const.T @ X_train_const)

    # Предсказание для новых данных
    y_pred = model.predict(X_new)

    # Вычисляем x*(X'X)⁻¹x' для каждой точки в X_new
    intervals = []
    for x in X_new_const:
        mat_part = x @ XtX_inv @ x.T
        se = sigma_e * np.sqrt(1 + mat_part)
        intervals.append(se)

    intervals = np.array(intervals).flatten()
    z_value = stats.norm.ppf(1 - alpha/2)  # 1.96 для alpha=0.05

    lower = y_pred - z_value * intervals
    upper = y_pred + z_value * intervals

    return y_pred, lower, upper
