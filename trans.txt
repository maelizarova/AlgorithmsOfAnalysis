"""
Отбор признаков для регрессии: важность из дерева и RFECV.
"""

import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.feature_selection import RFECV


def select_by_importance(X, y, max_features=None, importance_threshold=None, random_state=42):
    """
    Важность из LGBMRegressor. Оставить топ max_features или выше importance_threshold.
    """
    X_ = X.select_dtypes(include=[np.number]).copy()
    X_.fillna(X_.median(), inplace=True)
    m = lgb.LGBMRegressor(random_state=random_state, n_estimators=100, max_depth=4, verbosity=-1)
    m.fit(X_, y)
    imp = pd.Series(m.feature_importances_, index=X_.columns).sort_values(ascending=False)
    if importance_threshold is not None:
        selected = imp[imp >= importance_threshold].index.tolist()
    else:
        selected = imp.index.tolist()
    if max_features is not None:
        selected = imp.head(max_features).index.tolist()
    return selected, imp


def select_by_rfecv(X, y, estimator=None, min_features=10, step=50, cv=3, scoring="neg_mean_squared_error"):
    """
    RFECV: рекурсивное удаление с кросс-валидацией. Долго при большом числе фичей.
    estimator — модель с feature_importances_ или coef_; по умолчанию LGBMRegressor.
    """
    X_ = X.select_dtypes(include=[np.number]).copy()
    X_.fillna(X_.median(), inplace=True)
    if estimator is None:
        estimator = lgb.LGBMRegressor(n_estimators=50, max_depth=4, random_state=42, verbosity=-1)
    selector = RFECV(estimator=estimator, step=step, cv=cv, scoring=scoring, min_features_to_select=min_features)
    selector.fit(X_, y)
    return X_.columns[selector.support_].tolist(), selector
