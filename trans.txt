from typing import Dict, List, Union, Any, Optional
import pandas as pd
import numpy as np
import os
from sklearn.base import BaseEstimator
from sklearn.model_selection import GridSearchCV
from sklearn2pmml import sklearn2pmml, PMMLPipeline
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                           f1_score, roc_auc_score, log_loss,
                           mean_squared_error, mean_absolute_error,
                           mean_absolute_percentage_error, r2_score)
from lightgbm import early_stopping, log_evaluation


def grid_search_with_splits(
    train_data: pd.DataFrame,
    test_data: pd.DataFrame,
    oot_data: pd.DataFrame,
    targets: List[str],
    final_selected_features: Dict[str, List[str]],
    model: BaseEstimator,
    categorical_features: Optional[List[str]] = None,
    task_type: str = 'classification',
    param_grid: Optional[Dict[str, List[Any]]] = None,
    scoring: Optional[Union[str, List[str], Dict[str, Any]]] = None,
    cv: int = 5,
    threads: int = -1,
    pmml_output_path: Optional[str] = None,
    early_stopping_rounds: Optional[int] = None,
    verbose: int = 0
) -> Dict[str, Dict[str, Any]]:
    """
    Оптимизированная функция для подбора моделей с полной поддержкой:
    - Категориальных признаков (LightGBM/CatBoost)
    - Разделения на train/test/oot
    - Ранней остановки
    - Сохранения PMML
    
    Параметры:
        train_data: Тренировочные данные
        test_data: Валидационные данные
        oot_data: Out-of-time данные
        targets: Список целевых переменных
        final_selected_features: Словарь {target: [фичи]}
        model: Экземпляр модели (sklearn API)
        categorical_features: Список категориальных фичей
        task_type: 'classification' или 'regression'
        param_grid: Сетка параметров
        scoring: Метрики оценки
        cv: Число фолдов
        threads: Число потоков (-1 = все ядра)
        pmml_output_path: Путь для сохранения PMML
        early_stopping_rounds: Раунды ранней остановки
        verbose: Уровень логгирования
    """
    # Инициализация параметров
    categorical_features = categorical_features or []
    param_grid = param_grid or {}
    scoring = scoring or ('roc_auc' if task_type == 'classification' else 'neg_mean_squared_error')
    results = {}

    for target in targets:
        print(f"\n=== Обработка целевой переменной: {target} ===")
        
        # 1. Подготовка данных
        features = final_selected_features[target]
        cat_features = [f for f in categorical_features if f in features]
        
        # 2. Определение типа модели
        model_type = type(model).__name__.lower()
        is_lgbm = 'lgbm' in model_type
        is_catboost = 'catboost' in model_type
        
        # 3. Обработка категориальных признаков
        if cat_features and (is_lgbm or is_catboost):
            for df in [train_data, test_data, oot_data]:
                df[cat_features] = df[cat_features].astype('category')
            
            if is_lgbm:
                fit_params = {'estimator__categorical_feature': [features.index(f) for f in cat_features]}
            else:
                model.set_params(cat_features=cat_features)
                fit_params = {}
        else:
            fit_params = {}

        # 4. Настройка ранней остановки
        if early_stopping_rounds and (is_lgbm or is_catboost):
            X_val, y_val = test_data[features], test_data[target]
            fit_params.setdefault('estimator__eval_set', [(X_val, y_val)])
            
            if is_lgbm:
                fit_params.update({
                    'estimator__callbacks': [
                        early_stopping(early_stopping_rounds, verbose=verbose),
                        log_evaluation(verbose) if verbose > 0 else None
                    ],
                    'estimator__eval_metric': 'binary_logloss' if task_type == 'classification' else 'l2'
                })
            elif is_catboost:
                fit_params.update({
                    'estimator__early_stopping_rounds': early_stopping_rounds,
                    'estimator__verbose': verbose
                })

        # 5. Обучение модели
        pipeline = PMMLPipeline([('estimator', model)])
        grid_search = GridSearchCV(
            estimator=pipeline,
            param_grid=param_grid,
            scoring=scoring,
            cv=cv,
            n_jobs=threads if threads != -1 else None,
            verbose=verbose
        )
        
        print(f"Обучение модели на {len(features)} фичах...")
        grid_search.fit(train_data[features], train_data[target], **fit_params)
        
        # 6. Вычисление метрик
        best_model = grid_search.best_estimator_
        metrics = {}
        
        for name, df in [('train', train_data), ('test', test_data), ('oot', oot_data)]:
            X, y = df[features], df[target]
            pred = best_model.predict(X)
            
            if task_type == 'classification':
                metrics[name] = {
                    'accuracy': accuracy_score(y, pred),
                    'precision': precision_score(y, pred),
                    'recall': recall_score(y, pred),
                    'f1': f1_score(y, pred)
                }
                if hasattr(best_model, 'predict_proba'):
                    proba = best_model.predict_proba(X)[:, 1]
                    metrics[name].update({
                        'roc_auc': roc_auc_score(y, proba),
                        'log_loss': log_loss(y, proba)
                    })
            else:
                metrics[name] = {
                    'mse': mean_squared_error(y, pred),
                    'rmse': np.sqrt(mean_squared_error(y, pred)),
                    'mae': mean_absolute_error(y, pred),
                    'mape': mean_absolute_percentage_error(y, pred),
                    'r2': r2_score(y, pred)
                }

        # 7. Сохранение модели
        if pmml_output_path:
            os.makedirs(pmml_output_path, exist_ok=True)
            output_file = f"{pmml_output_path}/{target}_{model_type}.pmml"
            sklearn2pmml(best_model, output_file, with_repr=True)
            print(f"Модель сохранена в {output_file}")

        # 8. Сохранение результатов
        results[target] = {
            'model': best_model,
            'metrics': metrics,
            'best_params': grid_search.best_params_,
            'features': features,
            'categorical_features': cat_features
        }

        # 9. Вывод результатов
        print("\nЛучшие параметры:")
        for param, value in grid_search.best_params_.items():
            print(f"{param}: {value}")
        
        print("\nМетрики:")
        for dataset in ['train', 'test', 'oot']:
            print(f"\n{dataset.upper()}:")
            for metric, value in metrics[dataset].items():
                print(f"{metric}: {value:.4f}")

    return results


param_grid = {
    'boosting_type': ['gbdt', 'dart'],  # Тип бустинга
    'num_leaves': [31, 63, 127],        # Макс. количество листьев в дереве
    'max_depth': [-1, 5, 10],           # Глубина дерева (-1 = без ограничений)
    'learning_rate': [0.01, 0.05, 0.1], # Скорость обучения
    'n_estimators': [100, 200, 300],    # Количество деревьев
    'min_child_samples': [20, 50],      # Минимальное количество данных в листе
    'subsample': [0.8, 1.0],            # Доля строк для обучения каждого дерева
    'colsample_bytree': [0.8, 1.0],     # Доля признаков для обучения каждого дерева
    'reg_alpha': [0, 0.1, 1],           # L1-регуляризация
    'reg_lambda': [0, 0.1, 1],          # L2-регуляризация
}
