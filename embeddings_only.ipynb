{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import requests\n",
        "import re\n",
        "import logging\n",
        "import sys\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_gpt_oss_embedding(prompt, model=\"bge-m3:latest\"):\n",
        "    url = ''\n",
        "    api_key = ''\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Accept\": \"application/json\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"prompt\": prompt,\n",
        "        \"stream\": True\n",
        "    }\n",
        "    response = requests.post(url, json=payload, stream=False, headers=headers, timeout=120)\n",
        "    response.raise_for_status()\n",
        "    embedding_payload = json.loads(response.content.decode('utf-8'))\n",
        "    return embedding_payload.get('embedding')\n",
        "\n",
        "\n",
        "def clean_complaint_text(text):\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_embeddings(complaints, output_dir=\"embedding_results\", batch_size=100):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    results = []\n",
        "    errors = []\n",
        "    total = len(complaints)\n",
        "\n",
        "    for idx, complaint in enumerate(complaints, 1):\n",
        "        try:\n",
        "            cleaned_text = clean_complaint_text(complaint)\n",
        "            embedding = call_gpt_oss_embedding(cleaned_text)\n",
        "            embedding_dimension = len(embedding) if embedding else 0\n",
        "\n",
        "            results.append({\n",
        "                \"id\": idx,\n",
        "                \"original_text\": complaint,\n",
        "                \"cleaned_text\": cleaned_text,\n",
        "                \"embedding\": embedding,\n",
        "                \"embedding_dimension\": embedding_dimension,\n",
        "                \"processed_at\": datetime.now().isoformat()\n",
        "            })\n",
        "        except Exception as exc:\n",
        "            errors.append({\n",
        "                \"id\": idx,\n",
        "                \"original_text\": complaint,\n",
        "                \"error\": str(exc),\n",
        "                \"processed_at\": datetime.now().isoformat()\n",
        "            })\n",
        "            logging.error(f\"Ошибка при обработке записи {idx}: {exc}\")\n",
        "\n",
        "        if idx % batch_size == 0 or idx == total:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            chunk_path = os.path.join(output_dir, f\"embeddings_{timestamp}_upto_{idx}.json\")\n",
        "            payload = {\n",
        "                \"metadata\": {\n",
        "                    \"total\": total,\n",
        "                    \"saved_upto\": idx,\n",
        "                    \"timestamp\": timestamp,\n",
        "                    \"processed_at\": datetime.now().isoformat()\n",
        "                },\n",
        "                \"results\": results,\n",
        "                \"errors\": errors\n",
        "            }\n",
        "            with open(chunk_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(payload, f, ensure_ascii=False, indent=2)\n",
        "            results.clear()\n",
        "            errors.clear()\n",
        "            logging.info(f\"Сохранен промежуточный файл: {chunk_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('complaints.csv', encoding='utf-16', sep='\\t')\n",
        "complaints = list(df['Описание претензии'])\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_embeddings(\n",
        "    complaints=complaints[:10],  # замените на нужный диапазон\n",
        "    output_dir=\"embedding_results\",\n",
        "    batch_size=5\n",
        ")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
